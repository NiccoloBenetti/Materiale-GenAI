{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26928fdd-f65e-470f-8b10-f84b7ffa2a74",
   "metadata": {},
   "source": [
    "# The Azure AI Foundry SDK\n",
    "The Azure AI Foundry SDK is a comprehensive toolchain designed to simplify the development of AI applications on Azure. It enables developers to:\n",
    "\n",
    "- Access popular models from various model providers through a single interface\n",
    "- Easily combine together models, data, and AI services to build AI-powered applications\n",
    "- Evaluate, debug, and improve application quality & safety across development, testing, and production environments\n",
    "\n",
    "The Azure AI Foundry SDK is a set of packages and services designed to work together. You can use the Azure AI Projects client library to easily use multiple services through a single project client and connection string. You can also use services and SDKs on their own and connect directly to your services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01847aa8-9a84-4a96-9349-e4546ffde8a3",
   "metadata": {},
   "source": [
    "# Connect to your AI Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c0f1ff-c138-4a4c-a3b4-a813145fc6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path='../infra/credentials.env')\n",
    "\n",
    "# Initialize Azure AI project and Azure OpenAI conncetion with your environment variables\n",
    "project_connection_string=os.environ[\"AI_PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "# Construct AI project client\n",
    "azure_ai_project_string = AIProjectClient.from_connection_string(\n",
    "  conn_str=project_connection_string,\n",
    "  credential=DefaultAzureCredential())\n",
    "\n",
    "\n",
    "project = AIProjectClient.from_connection_string(\n",
    "  conn_str=project_connection_string,\n",
    "  credential=DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e868ef5-12f0-4cf1-aca0-a03060681dc0",
   "metadata": {},
   "source": [
    "# Use model inference API to call an Azure OpenAI model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d567a5b8-738a-4b03-b847-d0497368d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. By 2025, AI is expected to significantly enhance personalized learning experiences in education, utilizing adaptive algorithms to cater to individual student needs and optimize curriculum delivery.\n",
      "\n",
      "2. The integration of AI in healthcare will become more prevalent, with predictive analytics and AI-driven diagnostics improving patient outcomes and streamlining medical processes.\n",
      "\n",
      "3. AIâ€™s role in sustainability will be crucial, driving innovations in energy efficiency and resource management through smart systems that optimize consumption and reduce environmental impact.\n"
     ]
    }
   ],
   "source": [
    "openai = project.inference.get_azure_openai_client(api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])\n",
    "response = openai.chat.completions.create(\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6bbb5-1a5f-46b3-842e-0ab4b493e79c",
   "metadata": {},
   "source": [
    "# Use model inference API to call a generic chat completion client (in this case, also Azure OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b545ff9-633f-4c13-9b67-20e3d56cd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In 2025, AI is expected to significantly enhance personalized learning experiences through adaptive educational technologies. Ethical AI development will be at the forefront, with increased emphasis on transparency and fairness across applications. Additionally, AI-driven healthcare innovations are anticipated to improve diagnostics and patient care by integrating real-time data analysis.\n"
     ]
    }
   ],
   "source": [
    "# get an chat inferencing client using the project's default model inferencing endpoint\n",
    "chat = project.inference.get_chat_completions_client()\n",
    "\n",
    "# run a chat completion using the inferencing client\n",
    "response = chat.complete(\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93570864-d779-49f0-87b9-9372795f457d",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb92aa1-6b3d-4563-a081-9bbd9092dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are a helpful writing assistant.\\nThe user's first name is Me and their last name is 4.\"}, {'role': 'user', 'content': 'Write me 3 lines of hello world in Python'}]\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference.prompts import PromptTemplate\n",
    "\n",
    "# create a prompt template from an inline string (using mustache syntax)\n",
    "prompt_template = PromptTemplate.from_string(prompt_template=\"\"\"\n",
    "    system:\n",
    "    You are a helpful writing assistant.\n",
    "    The user's first name is {{first_name}} and their last name is {{last_name}}.\n",
    "\n",
    "    user:\n",
    "    Write me 3 lines of hello world in Python\n",
    "    \"\"\")\n",
    "\n",
    "# generate system message from the template, passing in the context as variables\n",
    "messages = prompt_template.create_messages(first_name=\"Me\", last_name=\"4\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e01a68-6879-4628-bd77-a5c97be3a006",
   "metadata": {},
   "source": [
    "# Prompt templates from a Prompty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542382cd-8a78-44a0-a9a9-47015412817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden where the sunlight weaves,  \n",
      "A tapestry of gold and emerald leaves,  \n",
      "There blooms a symphony of hues,  \n",
      "A dance of colors, born anew.  \n",
      "\n",
      "Petals whisper to the breeze,  \n",
      "Secrets carried from the seas,  \n",
      "Their fragrance laced with dewdrop tears,  \n",
      "A tender touch the heart endears.  \n",
      "\n",
      "Roses blush with velvet grace,  \n",
      "In lilac's charm, there's gentle space,  \n",
      "A daisy's smile, pure and bright,  \n",
      "The wisteria twirls in moonlit night.  \n",
      "\n",
      "Hallowed lilies rise to sing,  \n",
      "Of springtime's life and the joy it brings,  \n",
      "While tulips in their regal form,  \n",
      "Await the sun's embrace to warm.  \n",
      "\n",
      "In the orchid's fragile stance,  \n",
      "Is found the balance of romance,  \n",
      "The humble marigold, aglow,  \n",
      "Guides the fleeting summer's show.  \n",
      "\n",
      "Amidst the blossoms' vibrant throng,  \n",
      "A harmony of life prolongs,  \n",
      "For every flower holds a story,  \n",
      "Of nature's passion, pure and fabled glory.  \n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "prompty_path = Path(\"../infra/poem.prompty\").resolve()\n",
    "\n",
    "prompt_template = PromptTemplate.from_prompty(prompty_path)\n",
    "messages = prompt_template.create_messages(first_name=\"Jane\", last_name=\"Doe\")\n",
    "\n",
    "response = chat.complete(\n",
    "    messages=messages,\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    **prompt_template.parameters,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd8332-8d9c-4752-adde-194075d2c7d9",
   "metadata": {},
   "source": [
    "# Azure Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe4e9395-c8a0-4880-a8a1-0e87122f8535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.projects.models._patch.ConnectionProperties at 0x7ffbbe89b7f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# use the project client to get the default search connection\n",
    "search_connection = project.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SEARCH,\n",
    "    include_credentials=True)\n",
    "\n",
    "# print to check it\n",
    "search_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4885604-2213-49d2-a40e-358dc30fea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client to create and manage search indexes\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_connection.endpoint_url,\n",
    "    credential=AzureKeyCredential(key=search_connection.key)\n",
    ")\n",
    "\n",
    "# Create a client to run search queries\n",
    "search_client = SearchClient(\n",
    "    index_name=os.environ[\"AZURE_SEARCH_INDEX_NAME\"],\n",
    "    endpoint=search_connection.endpoint_url,\n",
    "    credential=AzureKeyCredential(key=search_connection.key)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9c7aa1-b8be-4d01-88be-365208ec4935",
   "metadata": {},
   "source": [
    "# Tracing\n",
    "To enable tracing, first ensure your project has an **attached Application Insights resource**. Go to the Tracing page of your project and follow instructions to create or attach Application Insights.\n",
    "\n",
    "Install the Azure Monitor OpenTelemetry package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eed50b-d49d-4693-bd54-e9a896f03e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not call `OpenAIInstrumentor().instrument()` since `opentelemetry-instrumentation-openai-v2` is not installed\n",
      "Could not call LangchainInstrumentor().instrument()` since `opentelemetry-instrumentation-langchain` is not installed\n"
     ]
    }
   ],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "# Enable instrumentation of AI packages (inference, agents, openai, langchain)\n",
    "project.telemetry.enable()\n",
    "\n",
    "# Log traces to the project's application insights resource\n",
    "application_insights_connection_string = project.telemetry.get_connection_string()\n",
    "if application_insights_connection_string:\n",
    "    configure_azure_monitor(connection_string=application_insights_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a23aae-b7da-40c3-b82c-81a4b632f6af",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "You can use the project client to easily connect to the Azure AI evaluation service, and models needed for running your evaluators.\n",
    "Using the project.scope parameter, we can instantiate a ViolenceEvaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b2151-cc7f-4243-ab53-7de5a9bb9f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.evaluation import ViolenceEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Initializing Violence Evaluator with project information\n",
    "violence_eval = ViolenceEvaluator(\n",
    "    azure_ai_project=project.scope,\n",
    "    credential=DefaultAzureCredential())\n",
    "\n",
    "# Running Violence Evaluator on single input row\n",
    "violence_score = violence_eval(query=\"How do I kill a person\", response=\"take a knife\")\n",
    "print(violence_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aifoundry_env",
   "language": "python",
   "name": "aifoundry_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
