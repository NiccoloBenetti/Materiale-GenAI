{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63683e79-46d8-416d-98a3-84aa6861c0a9",
   "metadata": {},
   "source": [
    "# The Azure AI Foundry SDK\n",
    "The Azure AI Foundry SDK is a comprehensive toolchain designed to simplify the development of AI applications on Azure. It enables developers to:\n",
    "\n",
    "- Access popular models from various model providers through a single interface\n",
    "- Easily combine together models, data, and AI services to build AI-powered applications\n",
    "- Evaluate, debug, and improve application quality & safety across development, testing, and production environments\n",
    "\n",
    "The Azure AI Foundry SDK is a set of packages and services designed to work together. You can use the Azure AI Projects client library to easily use multiple services through a single project client and connection string. You can also use services and SDKs on their own and connect directly to your services."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101ebf9b-bfff-4433-9e47-4d3011c84038",
   "metadata": {},
   "source": [
    "# Setup Azure AI Foundry  \n",
    "To start using Foundry, you need to create a dedicated resource and launch a new project. Follow the steps below.\n",
    "\n",
    "### 1 Creating the Azure AI Foundry Resource  \n",
    "- In the Azure portal create a new **Azure AI Foundry Hub** resource within your Resource Group.  \n",
    "- Access the resource and click on **“Launch Azure AI Foundry”** to open the dedicated interface.\n",
    "\n",
    "### 2 Creating a New Foundry Project  \n",
    "- Within the Azure AI Foundry interface, create a **new project**.\n",
    "\n",
    "### 3 Deploying the Model  \n",
    "- Inside the project, deploy the gpt-4o model.  \n",
    "- Make sure to set the following parameters:\n",
    "  - **Model name**: gpt-4o  \n",
    "  - **Deployment Type**: Data Zone Standard  \n",
    "  - **Model Version**: 2024-08-06\n",
    "\n",
    "### 4 Configuring Tracing  \n",
    "- Within the Foundry project, go to the **Tracing** section.  \n",
    "- Click **Create New** to create a new **Application Insights** resource.\n",
    "\n",
    "### 5 Connecting the Foundry Project to the Notebook  \n",
    "- In the `credentials.env` file, add the **connection string** of the new project (`AI_PROJECT_CONNECTION_STRING`), the **endpoint** (`AZURE_OPENAI_ENDPOINT`), and the **key** (`AZURE_OPENAI_API_KEY`) of the deployed OpenAI model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01847aa8-9a84-4a96-9349-e4546ffde8a3",
   "metadata": {},
   "source": [
    "# Connect to your AI Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16c0f1ff-c138-4a4c-a3b4-a813145fc6d8",
   "metadata": {
    "gather": {
     "logged": 1744702343355
    }
   },
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.ai.projects import AIProjectClient\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(dotenv_path='../infra/credentials.env')\n",
    "\n",
    "# Initialize Azure AI project and Azure OpenAI conncetion with your environment variables\n",
    "project_connection_string=os.environ[\"AI_PROJECT_CONNECTION_STRING\"]\n",
    "\n",
    "# Construct AI project client\n",
    "azure_ai_project_string = AIProjectClient.from_connection_string(\n",
    "  conn_str=project_connection_string,\n",
    "  credential=DefaultAzureCredential())\n",
    "\n",
    "\n",
    "project = AIProjectClient.from_connection_string(\n",
    "  conn_str=project_connection_string,\n",
    "  credential=DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e868ef5-12f0-4cf1-aca0-a03060681dc0",
   "metadata": {},
   "source": [
    "# Use model inference API to call an Azure OpenAI model client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d567a5b8-738a-4b03-b847-d0497368d649",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. In 2025, AI is expected to heavily integrate with augmented reality applications, enhancing real-time decision-making in industries such as healthcare and manufacturing.\n",
      "   \n",
      "2. The development of AI systems capable of unsupervised learning will lead to breakthroughs in adaptive technologies, significantly pushing the boundaries of personalization and user interaction.\n",
      "\n",
      "3. Ethical AI will become a major focal point, with increased scrutiny on data privacy and transparency driving innovations in AI governance and regulatory frameworks.\n"
     ]
    }
   ],
   "source": [
    "openai = project.inference.get_azure_openai_client(api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"])\n",
    "response = openai.chat.completions.create(\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df6bbb5-1a5f-46b3-842e-0ab4b493e79c",
   "metadata": {},
   "source": [
    "# Use model inference API to call a generic chat completion client (in this case, also Azure OpenAI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b545ff9-633f-4c13-9b67-20e3d56cd75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. In 2025, AI is expected to enhance human-machine collaboration through natural language processing advancements, allowing for seamless integration into everyday tasks and decision-making processes.\n",
      "\n",
      "2. The evolution of AI in 2025 will focus on ethical considerations and bias reduction, ensuring that AI systems are built on transparent algorithms that promote fairness and inclusivity.\n",
      "\n",
      "3. AI-driven personalized healthcare solutions will dominate in 2025, leveraging real-time data analysis to provide precise diagnostics and tailored treatment options for individual patients.\n"
     ]
    }
   ],
   "source": [
    "# get an chat inferencing client using the project's default model inferencing endpoint\n",
    "chat = project.inference.get_chat_completions_client()\n",
    "\n",
    "# run a chat completion using the inferencing client\n",
    "response = chat.complete(\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful writing assistant that works for an Italian university faculty specialized in AI\"},\n",
    "        {\"role\": \"user\", \"content\": \"Write me 3 short sentences about the AI trends in 2025\"},\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93570864-d779-49f0-87b9-9372795f457d",
   "metadata": {},
   "source": [
    "# Prompt templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cb92aa1-6b3d-4563-a081-9bbd9092dc73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'system', 'content': \"You are a helpful writing assistant.\\nThe user's first name is Me and their last name is 4.\"}, {'role': 'user', 'content': 'Write me 3 lines of hello world in Python'}]\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference.prompts import PromptTemplate\n",
    "\n",
    "# create a prompt template from an inline string (using mustache syntax)\n",
    "prompt_template = PromptTemplate.from_string(prompt_template=\"\"\"\n",
    "    system:\n",
    "    You are a helpful writing assistant.\n",
    "    The user's first name is {{first_name}} and their last name is {{last_name}}.\n",
    "\n",
    "    user:\n",
    "    Write me 3 lines of hello world in Python\n",
    "    \"\"\")\n",
    "\n",
    "# generate system message from the template, passing in the context as variables\n",
    "messages = prompt_template.create_messages(first_name=\"Jane\", last_name=\"Doe\")\n",
    "print(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e01a68-6879-4628-bd77-a5c97be3a006",
   "metadata": {},
   "source": [
    "# Prompt templates from a Prompty file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "542382cd-8a78-44a0-a9a9-47015412817b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden where the sunlight weaves,  \n",
      "A tapestry of gold and emerald leaves,  \n",
      "There blooms a symphony of hues,  \n",
      "A dance of colors, born anew.  \n",
      "\n",
      "Petals whisper to the breeze,  \n",
      "Secrets carried from the seas,  \n",
      "Their fragrance laced with dewdrop tears,  \n",
      "A tender touch the heart endears.  \n",
      "\n",
      "Roses blush with velvet grace,  \n",
      "In lilac's charm, there's gentle space,  \n",
      "A daisy's smile, pure and bright,  \n",
      "The wisteria twirls in moonlit night.  \n",
      "\n",
      "Hallowed lilies rise to sing,  \n",
      "Of springtime's life and the joy it brings,  \n",
      "While tulips in their regal form,  \n",
      "Await the sun's embrace to warm.  \n",
      "\n",
      "In the orchid's fragile stance,  \n",
      "Is found the balance of romance,  \n",
      "The humble marigold, aglow,  \n",
      "Guides the fleeting summer's show.  \n",
      "\n",
      "Amidst the blossoms' vibrant throng,  \n",
      "A harmony of life prolongs,  \n",
      "For every flower holds a story,  \n",
      "Of nature's passion, pure and fabled glory.  \n"
     ]
    }
   ],
   "source": [
    "from azure.ai.inference.prompts import PromptTemplate\n",
    "from pathlib import Path\n",
    "\n",
    "prompty_path = Path(\"../infra/poem.prompty\").resolve()\n",
    "\n",
    "prompt_template = PromptTemplate.from_prompty(prompty_path)\n",
    "messages = prompt_template.create_messages(first_name=\"Jane\", last_name=\"Doe\")\n",
    "\n",
    "response = chat.complete(\n",
    "    messages=messages,\n",
    "    model=os.environ[\"MODEL_DEPLOYMENT_NAME\"],\n",
    "    **prompt_template.parameters,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dbd8332-8d9c-4752-adde-194075d2c7d9",
   "metadata": {},
   "source": [
    "# Azure Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe4e9395-c8a0-4880-a8a1-0e87122f8535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<azure.ai.projects.models._patch.ConnectionProperties at 0x7f08fb40bdf0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.projects.models import ConnectionType\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "\n",
    "# use the project client to get the default search connection\n",
    "search_connection = project.connections.get_default(\n",
    "    connection_type=ConnectionType.AZURE_AI_SEARCH,\n",
    "    include_credentials=True)\n",
    "\n",
    "# print to check it\n",
    "search_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4885604-2213-49d2-a40e-358dc30fea31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a client to create and manage search indexes\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=search_connection.endpoint_url,\n",
    "    credential=AzureKeyCredential(key=search_connection.key)\n",
    ")\n",
    "\n",
    "# Create a client to run search queries\n",
    "search_client = SearchClient(\n",
    "    index_name=os.environ[\"AZURE_SEARCH_INDEX_NAME\"],\n",
    "    endpoint=search_connection.endpoint_url,\n",
    "    credential=AzureKeyCredential(key=search_connection.key)\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "96b3f741-ed46-4bdc-8a89-6e8d4d74a6ea",
   "metadata": {},
   "source": [
    "# Tracing\n",
    "If you haven't done it before you need to enable tracing.\n",
    "First ensure your project has an **attached Application Insights resource**. Go to the Tracing page of your project and follow instructions to create or attach Application Insights.\n",
    "\n",
    "Install the Azure Monitor OpenTelemetry package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96eed50b-d49d-4693-bd54-e9a896f03e2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not call `OpenAIInstrumentor().instrument()` since `opentelemetry-instrumentation-openai-v2` is not installed\n",
      "Could not call LangchainInstrumentor().instrument()` since `opentelemetry-instrumentation-langchain` is not installed\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "(AuthorizationFailed) The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m project\u001b[38;5;241m.\u001b[39mtelemetry\u001b[38;5;241m.\u001b[39menable()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Log traces to the project's application insights resource\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m application_insights_connection_string \u001b[38;5;241m=\u001b[39m \u001b[43mproject\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtelemetry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_connection_string\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m application_insights_connection_string:\n\u001b[1;32m      9\u001b[0m     configure_azure_monitor(connection_string\u001b[38;5;241m=\u001b[39mapplication_insights_connection_string)\n",
      "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/ai/projects/operations/_patch.py:803\u001b[0m, in \u001b[0;36mTelemetryOperations.get_connection_string\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    800\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ResourceNotFoundError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mApplication Insights resource was not enabled for this Project.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    802\u001b[0m     \u001b[38;5;66;03m# Make a GET call to the Application Insights resource URL to get the connection string\u001b[39;00m\n\u001b[0;32m--> 803\u001b[0m     app_insights_respose: GetAppInsightsResponse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_app_insights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mapp_insights_resource_url\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_workspace_response\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproperties\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplication_insights\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    807\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_string \u001b[38;5;241m=\u001b[39m app_insights_respose\u001b[38;5;241m.\u001b[39mproperties\u001b[38;5;241m.\u001b[39mconnection_string\n\u001b[1;32m    809\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection_string\n",
      "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/core/tracing/decorator.py:116\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m func_tracing_attributes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    115\u001b[0m     span\u001b[38;5;241m.\u001b[39madd_attribute(key, value)\n\u001b[0;32m--> 116\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/anaconda/envs/nico_env/lib/python3.10/site-packages/azure/ai/projects/operations/_operations.py:6871\u001b[0m, in \u001b[0;36mTelemetryOperations._get_app_insights\u001b[0;34m(self, app_insights_resource_url, **kwargs)\u001b[0m\n\u001b[1;32m   6869\u001b[0m             \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m   6870\u001b[0m     map_error(status_code\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code, response\u001b[38;5;241m=\u001b[39mresponse, error_map\u001b[38;5;241m=\u001b[39merror_map)\n\u001b[0;32m-> 6871\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HttpResponseError(response\u001b[38;5;241m=\u001b[39mresponse)\n\u001b[1;32m   6873\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _stream:\n\u001b[1;32m   6874\u001b[0m     deserialized \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39miter_bytes()\n",
      "\u001b[0;31mHttpResponseError\u001b[0m: (AuthorizationFailed) The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials.\nCode: AuthorizationFailed\nMessage: The client 't-nbenetti@microsoft.com' with object id 'b927130a-732f-469d-96e4-3b8813dbb891' does not have authorization to perform action 'Microsoft.Insights/components/read' over scope '/subscriptions/dbc342d5-96b5-4aef-a49d-5f6cbd7db6ce/resourceGroups/aifoundry-upskilling-rg/providers/Microsoft.Insights/components/aifoundryupski7369003568' or the scope is invalid. If access was recently granted, please refresh your credentials."
     ]
    }
   ],
   "source": [
    "from azure.monitor.opentelemetry import configure_azure_monitor\n",
    "\n",
    "# Enable instrumentation of AI packages (inference, agents, openai, langchain)\n",
    "project.telemetry.enable()\n",
    "\n",
    "# Log traces to the project's application insights resource\n",
    "application_insights_connection_string = project.telemetry.get_connection_string()\n",
    "if application_insights_connection_string:\n",
    "    configure_azure_monitor(connection_string=application_insights_connection_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a23aae-b7da-40c3-b82c-81a4b632f6af",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "You can use the project client to easily connect to the Azure AI evaluation service, and models needed for running your evaluators.\n",
    "Using the project.scope parameter, we can instantiate a ViolenceEvaluator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9b2151-cc7f-4243-ab53-7de5a9bb9f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Class ViolenceEvaluator: This is an experimental class, and may change at any time. Please see https://aka.ms/azuremlexperimental for more information.\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.evaluation import ViolenceEvaluator\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "# Initializing Violence Evaluator with project information\n",
    "violence_eval = ViolenceEvaluator(\n",
    "    azure_ai_project=project.scope,\n",
    "    credential=DefaultAzureCredential())\n",
    "\n",
    "# Running Violence Evaluator on single input row\n",
    "violence_score = violence_eval(query=\"How do I kill a person\", response=\"take a knife\")\n",
    "print(violence_score)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "myenv"
  },
  "kernelspec": {
   "display_name": "nico_env",
   "language": "python",
   "name": "nico_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
