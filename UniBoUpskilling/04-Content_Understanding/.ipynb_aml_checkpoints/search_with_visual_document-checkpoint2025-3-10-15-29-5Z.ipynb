{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Document Search with Azure Content Understanding\n",
    "\n",
    "Source: https://github.com/Azure-Samples/azure-ai-search-with-content-understanding-python\n",
    "\n",
    "(slightly modified for training purposes)\n",
    "\n",
    "## Objective\n",
    "This document illustrates an example workflow for how to leverage the Azure AI Content Understanding API to enhance the quality of document search.\n",
    "\n",
    "The sample will demonstrate the following steps:\n",
    "1. Extract the layout and content of a document using Azure AI Document Intelligence.\n",
    "2. For each figure in the document, extract its content with a custom analyzer using Azure AI Content Understanding, and insert it into the corresponding location in the document content.\n",
    "2. Chunk and embed the document content with LangChain and Azure OpenAI, and index them with Azure Search to generate an Azure Search index.\n",
    "3. Utilize an OpenAI chat model to search through content in the document with a natural language query.\n",
    "\n",
    "\n",
    "## Pre-requisites\n",
    "1. Follow the [README](README.md) to create the required resources for this sample.\n",
    "1. Install the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -r ../requirements_aisearch.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from datetime import datetime # added for customizing AZURE_SEARCH_INDEX_NAME (if needed)\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Load and validate Azure AI Services configs\n",
    "AZURE_AI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_SERVICE_API_VERSION = os.getenv(\"AZURE_AI_SERVICE_API_VERSION\") or \"2024-12-01-preview\"\n",
    "AZURE_DOCUMENT_INTELLIGENCE_API_VERSION = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_API_VERSION\") or \"2024-11-30\"\n",
    "\n",
    "# Load and validate Azure OpenAI configs\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_CHAT_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_CHAT_API_VERSION = os.getenv(\"AZURE_OPENAI_CHAT_API_VERSION\") or \"2024-08-01-preview\"\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.getenv(\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\")\n",
    "AZURE_OPENAI_EMBEDDING_API_VERSION = os.getenv(\"AZURE_OPENAI_EMBEDDING_API_VERSION\") or \"2023-05-15\"\n",
    "\n",
    "# Load and validate Azure Search Services configs\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_SEARCH_INDEX_NAME = os.getenv(\"AZURE_SEARCH_INDEX_NAME\") or \"sample-index-visual-doc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Azure AI Services endpoint: https://ep-ai-services.services.ai.azure.com/\n"
     ]
    }
   ],
   "source": [
    "print(f\"Current Azure AI Services endpoint: {AZURE_AI_SERVICE_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Azure OpenAI endpoint: {AZURE_OPENAI_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Azure AI Search endpoint: {AZURE_SEARCH_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Get the path to the file that will be analyzed\n",
    "# Sample report source: https://www.imf.org/en/Publications/CR/Issues/2024/07/18/United-States-2024-Article-IV-Consultation-Press-Release-Staff-Report-and-Statement-by-the-552100\n",
    "file = Path(\"assets/reports/sample_report_3pg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('assets/reports/sample_report_3pg.pdf')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom analyzer using chart and diagram understanding template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import uuid\n",
    "import pandas as pd # added for visualizing existing analyzers into a df\n",
    "import logging # added for visualizing response details from methods e.g. delete_analyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only if necessary, add the parent directory to the path to use shared modules\n",
    "# parent_dir = Path(Path.cwd()).parent\n",
    "# sys.path.append(str(parent_dir))\n",
    "\n",
    "# import the utility class AzureContentUnderstandingClient, which is a wrapper around the Azure Content Understanding REST API client\n",
    "from python.content_understanding_client import AzureContentUnderstandingClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "credential = DefaultAzureCredential()\n",
    "token_provider = get_bearer_token_provider(credential, \"https://cognitiveservices.azure.com/.default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     credential = DefaultAzureCredential()\n",
    "#     # Test token acquisition\n",
    "#     token = credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "#     print(\"Successfully acquired token!\")\n",
    "# except Exception as e:\n",
    "#     print(f\"Authentication failed: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create content understanding client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_understanding_client = AzureContentUnderstandingClient(\n",
    "    endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "    api_version=AZURE_AI_SERVICE_API_VERSION,\n",
    "    # subscription_key= \"715b91dd-7c91-4bf2-8987-8640c7168071\",\n",
    "    token_provider=token_provider,\n",
    "    # x_ms_useragent=\"azure-ai-content-understanding-python/search_with_visusal_document\", # This header is used for sample usage telemetry, please comment out this line if you want to opt out.\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create an analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get path to sample template\n",
    "ANALYZER_TEMPLATE_PATH = \"analyzer_templates/image_chart_diagram_understanding.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating analyzer with ID 'content-understanding-search-sample-97062efd-e55f-4a1a-b276-1dd504e5d6da'...\n"
     ]
    }
   ],
   "source": [
    "# Create analyzer\n",
    "ANALYZER_ID = \"content-understanding-search-sample-\" + str(uuid.uuid4())\n",
    "print(f\"Creating analyzer with ID '{ANALYZER_ID}'...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    response = content_understanding_client.begin_create_analyzer(ANALYZER_ID, analyzer_template_path=ANALYZER_TEMPLATE_PATH)\n",
    "    result = content_understanding_client.poll_result(response)\n",
    "    print(f'Analyzer details for {result[\"result\"][\"analyzerId\"]}:')\n",
    "    # print(json.dumps(result, indent=2))\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"Error in creating analyzer. Please double-check your analysis settings.\\nIf there is a conflict, you can delete the analyzer and then recreate it, or move to the next cell and use the existing analyzer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"analyzerId\": \"content-understanding-search-sample-97062efd-e55f-4a1a-b276-1dd504e5d6da\",\n",
      "  \"description\": \"Extract detailed structured information from charts and diagrams.\",\n",
      "  \"createdAt\": \"2025-04-02T17:33:07Z\",\n",
      "  \"lastModifiedAt\": \"2025-04-02T17:33:07Z\",\n",
      "  \"config\": {\n",
      "    \"returnDetails\": false,\n",
      "    \"disableContentFiltering\": false\n",
      "  },\n",
      "  \"fieldSchema\": {\n",
      "    \"name\": \"ChartsAndDiagrams\",\n",
      "    \"fields\": {\n",
      "      \"Title\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Verbatim title of the chart.\"\n",
      "      },\n",
      "      \"ChartType\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"The type of chart.\",\n",
      "        \"enum\": [\n",
      "          \"area\",\n",
      "          \"bar\",\n",
      "          \"box\",\n",
      "          \"bubble\",\n",
      "          \"candlestick\",\n",
      "          \"funnel\",\n",
      "          \"heatmap\",\n",
      "          \"histogram\",\n",
      "          \"line\",\n",
      "          \"pie\",\n",
      "          \"radar\",\n",
      "          \"rings\",\n",
      "          \"rose\",\n",
      "          \"treemap\"\n",
      "        ],\n",
      "        \"enumDescriptions\": {\n",
      "          \"histogram\": \"Continuous values on the x-axis, which distinguishes it from bar.\",\n",
      "          \"rose\": \"In contrast to pie charts, the sectors are of equal angles and differ in how far each sector extends from the center of the circle.\"\n",
      "        }\n",
      "      },\n",
      "      \"TopicKeywords\": {\n",
      "        \"type\": \"array\",\n",
      "        \"description\": \"Relevant topics associated with the chart, used for tagging.\",\n",
      "        \"items\": {\n",
      "          \"type\": \"string\",\n",
      "          \"examples\": [\n",
      "            \"Business and finance\",\n",
      "            \"Arts and culture\",\n",
      "            \"Education and academics\"\n",
      "          ]\n",
      "        }\n",
      "      },\n",
      "      \"DetailedDescription\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Detailed description of the chart or diagram, not leaving out any key information. Include numbers, trends, and other details.\"\n",
      "      },\n",
      "      \"Summary\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Detailed summary of the chart, including highlights and takeaways.\"\n",
      "      },\n",
      "      \"MarkdownDataTable\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"Underlying data of the chart in tabular markdown format. Give markdown output with valid syntax and accurate numbers, and fill any uncertain values with empty cells. If not applicable, output an empty string.\"\n",
      "      },\n",
      "      \"AxisTitles\": {\n",
      "        \"type\": \"object\",\n",
      "        \"description\": \"Titles of the x and y axes.\",\n",
      "        \"properties\": {\n",
      "          \"xAxisTitle\": {\n",
      "            \"type\": \"string\"\n",
      "          },\n",
      "          \"yAxisTitle\": {\n",
      "            \"type\": \"string\"\n",
      "          }\n",
      "        }\n",
      "      },\n",
      "      \"FootnotesAndAnnotations\": {\n",
      "        \"type\": \"string\",\n",
      "        \"description\": \"All footnotes and textual annotations in the chart or diagram.\"\n",
      "      }\n",
      "    }\n",
      "  },\n",
      "  \"warnings\": [],\n",
      "  \"status\": \"ready\",\n",
      "  \"scenario\": \"image\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check if the analyzer was created successfully\n",
    "result = content_understanding_client.get_analyzer_detail_by_id(ANALYZER_ID)\n",
    "print(json.dumps(result, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze document layout and compose with figure descriptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions for document-figure composition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install PyMuPDF\n",
    "\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import AnalyzeResult\n",
    "from azure.ai.documentintelligence.models import AnalyzeDocumentRequest\n",
    "import fitz\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define helper functions for document-figure composition\n",
    "def insert_figure_contents(md_content, figure_contents, span_offsets):\n",
    "    \"\"\"\n",
    "    Inserts the figure content for each of the provided figures in figure_contents\n",
    "    before the span offset of that figure in the given markdown content.\n",
    "\n",
    "    Args:\n",
    "    - md_content (str): The original markdown content.\n",
    "    - figure_contents (list[str]): The contents of each figure to insert.\n",
    "    - span_offsets (list[int]): The span offsets of each figure in order. These should be sorted and strictly increasing.\n",
    "\n",
    "    Returns:\n",
    "    - str: The modified markdown content with the the figure contents prepended to each figure's span.\n",
    "    \"\"\"\n",
    "    # NOTE: In this notebook, we only alter the Markdown content returned by the Document Intelligence API,\n",
    "    # and not the per-element spans in the API response. Thus, after figure content insertion, these per-element spans will be inaccurate.\n",
    "    # This may impact use cases like citation page number calculation.\n",
    "    # Additional code may be needed to correct the spans or otherwise infer the page numbers for each citation.\n",
    "    # The main purpose of the notebook is to show the feasibility of using Content Understanding with Azure Search for RAG chat applications.\n",
    "\n",
    "    # Validate span_offsets are sorted and strictly increasing\n",
    "    if span_offsets != sorted(span_offsets) or not all([o < span_offsets[i + 1] for i, o in enumerate(span_offsets) if i < len(span_offsets) - 1]):\n",
    "        raise ValueError(\"span_offsets should be sorted and strictly increasing.\")\n",
    "\n",
    "    # Split the content based on the provided spans\n",
    "    parts = []\n",
    "    preamble = None\n",
    "    for i, offset in enumerate(span_offsets):\n",
    "        if i == 0 and offset > 0:\n",
    "            preamble = md_content[0:offset]\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
    "        elif i == len(span_offsets) - 1:\n",
    "            parts.append(md_content[offset:])\n",
    "        else:\n",
    "            parts.append(md_content[offset:span_offsets[i + 1]])\n",
    "\n",
    "    # Join the parts back together with the figure content inserted\n",
    "    modified_content = \"\"\n",
    "    if preamble:\n",
    "        modified_content += preamble\n",
    "    for i, part in enumerate(parts):\n",
    "        modified_content += f\"<!-- FigureContent=\\\"{figure_contents[i]}\\\" -->\" + part\n",
    "\n",
    "    return modified_content\n",
    "\n",
    "def crop_image_from_pdf_page(pdf_path, page_number, bounding_box):\n",
    "    \"\"\"\n",
    "    Crops a region from a given page in a PDF and returns it as an image.\n",
    "\n",
    "    Args:    \n",
    "    - pdf_path (pathlib.Path): Path to the PDF file.\n",
    "    - page_number (int): The page number to crop from (0-indexed).\n",
    "    - bounding_box (tuple): A tuple of (x0, y0, x1, y1) coordinates for the bounding box.\n",
    "    \n",
    "    Returns:\n",
    "    - PIL.Image: A PIL Image of the cropped area.\n",
    "    \"\"\"\n",
    "    doc = fitz.open(pdf_path)\n",
    "    page = doc.load_page(page_number)\n",
    "    \n",
    "    # Cropping the page. The rect requires the coordinates in the format (x0, y0, x1, y1).\n",
    "    bbx = [x * 72 for x in bounding_box]\n",
    "    rect = fitz.Rect(bbx)\n",
    "    pix = page.get_pixmap(matrix=fitz.Matrix(300 / 72, 300 / 72), clip=rect)\n",
    "    \n",
    "    img = Image.frombytes(\"RGB\", [pix.width, pix.height], pix.samples)\n",
    "    \n",
    "    doc.close()\n",
    "\n",
    "    return img\n",
    "\n",
    "def format_content_understanding_result(content_understanding_result):\n",
    "    \"\"\"\n",
    "    Formats the JSON output of the Content Understanding result as Markdown for downstream usage in text.\n",
    "    \n",
    "    Args:\n",
    "    - content_understanding_result (dict): A dictionary containing the output from Content Understanding.\n",
    "\n",
    "    Returns:\n",
    "    - str: A Markdown string of the result content.\n",
    "    \"\"\"\n",
    "    def _format_result(key, result):\n",
    "        result_type = result[\"type\"]\n",
    "        if result_type in [\"string\", \"integer\", \"number\", \"boolean\"]:\n",
    "            return f\"**{key}**: \" + str(result[f'value{result_type.capitalize()}']) + \"\\n\"\n",
    "        elif result_type == \"array\":\n",
    "            return f\"**{key}**: \" + ', '.join([str(result[\"valueArray\"][i][f\"value{r['type'].capitalize()}\"]) for i, r in enumerate(result[\"valueArray\"])]) + \"\\n\"\n",
    "        elif result_type == \"object\":\n",
    "            return f\"**{key}**\\n\" + ''.join([_format_result(f\"{key}.{k}\", result[\"valueObject\"][k]) for k in result[\"valueObject\"]])\n",
    "\n",
    "    fields = content_understanding_result['result']['contents'][0]['fields']\n",
    "    markdown_result = \"\"\n",
    "    for field in fields:\n",
    "        markdown_result += _format_result(field, fields[field])\n",
    "\n",
    "    return markdown_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract figures and run content understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('assets/reports/sample_report_3pg.pdf')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed computation time: ~1 minute for 3 pages\n",
    "# the output is cached in a file called 'sample_report.cache'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting figure contents with Content Understanding.\n",
      "Figure 1 contents:\n",
      "**Title**: 2023 Real GDP\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Global economy\n",
      "**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, approximately 1.0%. Japan, Canada, and the Euro Area have negative deviations, each around -1.0%. The United Kingdom shows a significant negative deviation of about -4.0%. The G-20 Emerging Markets (EMs) also have a negative deviation, slightly less than -3.0%.\n",
      "**Summary**: The chart illustrates the 2023 Real GDP deviations from pre-crisis trends for several major economies. The United States is the only economy with a positive deviation, indicating growth above the pre-crisis trend. In contrast, the UK shows the largest negative deviation, suggesting a significant downturn compared to its pre-crisis trend. Other regions, including Japan, Canada, the Euro Area, and G-20 Emerging Markets, also exhibit negative deviations, indicating economic performance below pre-crisis expectations.\n",
      "**MarkdownDataTable**: | Region     | Percent Deviation |\n",
      "|------------|------------------|\n",
      "| US         | 1.0              |\n",
      "| Japan      | -1.0             |\n",
      "| Canada     | -1.0             |\n",
      "| Euro Area  | -1.0             |\n",
      "| UK         | -4.0             |\n",
      "| G-20 EMs   | -3.0             |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: \n",
      "**AxisTitles.yAxisTitle**: Percent Deviation\n",
      "**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n",
      "\n",
      "Figure 2 contents:\n",
      "**Title**: Federal Government Spending\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Government\n",
      "**DetailedDescription**: The chart displays federal government spending as a percentage of GDP, relative to the 2019 level, from 2020 to 2023. In 2020, spending was approximately 9% of GDP, with the largest portion attributed to individuals, followed by SLGs (State and Local Governments), others, and businesses. In 2021, spending decreased to around 5% of GDP, with individuals still being the largest category, followed by SLGs, others, and businesses. By 2022, spending further decreased to about 1% of GDP, with individuals and SLGs being the primary categories. In 2023, spending was slightly above 0% of GDP, with individuals and SLGs being the main contributors.\n",
      "**Summary**: The chart illustrates a significant decrease in federal government spending as a percentage of GDP from 2020 to 2023, relative to the 2019 level. The spending was highest in 2020, driven mainly by expenditures for individuals, and decreased steadily over the years, with individuals and SLGs consistently being the largest categories.\n",
      "**MarkdownDataTable**: | Year | Individuals | Businesses | SLGs | Others |\n",
      "|------|-------------|------------|------|--------|\n",
      "| 2020 | 6           | 0.5        | 1.5  | 1      |\n",
      "| 2021 | 3.5         | 0.5        | 0.5  | 0.5    |\n",
      "| 2022 | 0.5         | 0          | 0.5  | 0      |\n",
      "| 2023 | 0.5         | 0          | 0    | 0      |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: Year\n",
      "**AxisTitles.yAxisTitle**: Percent of GDP\n",
      "**FootnotesAndAnnotations**: Source: U.S. Department of Treasury; Small Business Administration; Congressional Research Services; Office of Management and Budget; IMF staff calculation.\n",
      "Note: 'Federal spending is measured as the increase relative to the 2019 level; Others included defense spending, capital investment, interest spending, and other items not directly attributable to firms, households, or subnational governments.'\n",
      "\n",
      "Figure 3 contents:\n",
      "**Title**: General Government Structural Primary Balance and Fiscal Impulse\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Fiscal policy, Government\n",
      "**DetailedDescription**: The chart compares the general government structural primary balance and fiscal impulse between the US and the Euro Area. The structural primary balance for the US in 2019 was approximately -3, while for the Euro Area it was slightly better, around -2. The fiscal impulse, which represents cumulative deficits in excess of 2019, shows a significant increase for both regions. The US fiscal impulse is around -8, while the Euro Area fiscal impulse is even larger, reaching approximately -12.\n",
      "**Summary**: The chart illustrates the fiscal positions of the US and Euro Area before the pandemic in 2019 and the fiscal impulse during the pandemic. Both regions had negative structural primary balances in 2019, with the Euro Area slightly better than the US. The fiscal impulse during the pandemic was substantial, with the Euro Area showing a larger increase in cumulative deficits compared to the US.\n",
      "**MarkdownDataTable**: | Region     | Pre-pandemic (2019) | Fiscal impulse |\n",
      "|------------|---------------------|----------------|\n",
      "| US         | -3                  | -8             |\n",
      "| Euro Area  | -2                  | -12            |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: General Government Structural Primary Balance and Fiscal Impulse\n",
      "**AxisTitles.yAxisTitle**: Value\n",
      "**FootnotesAndAnnotations**: \n",
      "\n",
      "Figure 4 contents:\n",
      "**Title**: Asset Price Indices (Dec 2019 = 100)\n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Economics, Real estate, Stock market\n",
      "**DetailedDescription**: The chart shows the trend of two asset price indices from December 2019 to September 2023, with December 2019 as the base period (index value = 100). The Case-Shiller House Price Index is represented by a blue line, and the S&P 500 Index is represented by an orange line. Initially, both indices were close to the base value of 100. The S&P 500 Index experienced a sharp decline in early 2020, followed by a rapid recovery and continued growth, peaking around mid-2021. It then fluctuated with a downward trend until early 2023, after which it rose sharply again, reaching approximately 160 by September 2023. The Case-Shiller House Price Index showed a steady increase throughout the period, with minor fluctuations, reaching around 140 by September 2023.\n",
      "**Summary**: The chart compares the Case-Shiller House Price Index and the S&P 500 Index from December 2019 to September 2023. The S&P 500 Index experienced significant volatility, with a sharp drop in early 2020 and a peak in mid-2021, followed by fluctuations and a strong rise in 2023. The Case-Shiller House Price Index showed a steady upward trend, reaching 140 by September 2023.\n",
      "**MarkdownDataTable**: | Date     | Case-Shiller House Price Index | S&P 500 Index |\n",
      "|----------|--------------------------------|---------------|\n",
      "| Dec-2019 | 100                            | 100           |\n",
      "| Sep-2020 | 110                            | 120           |\n",
      "| Jun-2021 | 130                            | 150           |\n",
      "| Mar-2022 | 135                            | 140           |\n",
      "| Dec-2022 | 140                            | 130           |\n",
      "| Sep-2023 | 140                            | 160           |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: \n",
      "**AxisTitles.yAxisTitle**: Index Value\n",
      "**FootnotesAndAnnotations**: Source: S&P Dow Jones Indices LLC; Haver.\n",
      "\n",
      "Figure 5 contents:\n",
      "**Title**: (US$ trillions, constant 2019 prices)\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Income distribution\n",
      "**DetailedDescription**: The bar chart displays the distribution of income across different percentiles of the population for the years 2009, 2019, and 2023, measured in US$ trillions at constant 2019 prices. The income is divided into five groups: Bottom 20%, 21-40%, 41-60%, 61-80%, and Top 20%. The Top 20% group is represented on the right-hand side (RHS) of the chart. In 2009, the Bottom 20% had the lowest income, while the Top 20% had the highest. Over the years, income has increased across all groups, with the Top 20% showing the most significant increase from approximately 12 trillion in 2009 to over 16 trillion in 2023. The 61-80% group also shows a notable increase from around 6 trillion in 2009 to over 8 trillion in 2023.\n",
      "**Summary**: The chart illustrates the growth in income across different population percentiles from 2009 to 2023, with the Top 20% experiencing the most significant increase. Income has risen steadily across all groups, reflecting economic growth over the period.\n",
      "**MarkdownDataTable**: | Percentile | 2009 Income (US$ trillions) | 2019 Income (US$ trillions) | 2023 Income (US$ trillions) |\n",
      "|------------|-----------------------------|-----------------------------|-----------------------------|\n",
      "| Bottom 20% |                             |                             |                             |\n",
      "| 21-40%     |                             |                             |                             |\n",
      "| 41-60%     |                             |                             |                             |\n",
      "| 61-80%     |                             |                             |                             |\n",
      "| Top 20%    |                             |                             |                             |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: Percentile\n",
      "**AxisTitles.yAxisTitle**: Income (US$ trillions)\n",
      "**FootnotesAndAnnotations**: Source: Federal Reserve; Bureau of Economic Analysis\n",
      "\n",
      "Figure 6 contents:\n",
      "**Title**: \n",
      "**ChartType**: line\n",
      "**TopicKeywords**: Business and finance, Economics, Federal Reserve\n",
      "**DetailedDescription**: The line chart shows a trend over time from 2018 Q1 to 2024 Q1. The values start at approximately 2.5 in 2018 Q1, showing a slight increase and fluctuation until 2020 Q1. From 2020 Q1, there is a sharp decline reaching a low point of approximately 1.5 in 2021 Q1. After this point, the values begin to rise steadily, surpassing the initial value and reaching approximately 3 by 2024 Q1.\n",
      "**Summary**: The chart illustrates a time series trend from 2018 Q1 to 2024 Q1, showing an initial stable period followed by a sharp decline around 2020 Q1, and then a steady recovery and growth reaching a peak in 2024 Q1.\n",
      "**MarkdownDataTable**: | Quarter | Value |\n",
      "|---------|-------|\n",
      "| 2018Q1  | 2.5   |\n",
      "| 2018Q4  | 2.6   |\n",
      "| 2019Q3  | 2.7   |\n",
      "| 2020Q2  | 2.4   |\n",
      "| 2021Q1  | 1.5   |\n",
      "| 2021Q4  | 2.0   |\n",
      "| 2022Q3  | 2.5   |\n",
      "| 2023Q2  | 2.8   |\n",
      "| 2024Q1  | 3.0   |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**: Quarter\n",
      "**AxisTitles.yAxisTitle**: Value\n",
      "**FootnotesAndAnnotations**: Source: Federal Reserve.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run Content Understanding on each figure, format figure contents, and insert figure contents into corresponding document locations\n",
    "with open(file, 'rb') as f:\n",
    "    pdf_bytes = f.read()\n",
    "\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=AZURE_AI_SERVICE_ENDPOINT,\n",
    "        api_version=AZURE_DOCUMENT_INTELLIGENCE_API_VERSION,\n",
    "        credential=credential,\n",
    "        output=str('figures')\n",
    "    )\n",
    "\n",
    "    poller = document_intelligence_client.begin_analyze_document(\n",
    "        \"prebuilt-layout\",\n",
    "        AnalyzeDocumentRequest(bytes_source=pdf_bytes),\n",
    "        output=[str('figures')],\n",
    "        features=['ocrHighResolution'],\n",
    "        output_content_format=\"markdown\"\n",
    "    )\n",
    "\n",
    "    result: AnalyzeResult = poller.result()\n",
    "    \n",
    "    md_content = result.content\n",
    "\n",
    "    figure_contents = []\n",
    "    if result.figures:\n",
    "        print(\"Extracting figure contents with Content Understanding.\")\n",
    "        for figure_idx, figure in enumerate(result.figures):\n",
    "            for region in figure.bounding_regions:\n",
    "                    # Uncomment the below to print out the bounding regions of each figure\n",
    "                    # print(f\"Figure {figure_idx + 1} body bounding regions: {region}\")\n",
    "                    # To learn more about bounding regions, see https://aka.ms/bounding-region\n",
    "                    bounding_box = (\n",
    "                            region.polygon[0],  # x0 (left)\n",
    "                            region.polygon[1],  # y0 (top\n",
    "                            region.polygon[4],  # x1 (right)\n",
    "                            region.polygon[5]   # y1 (bottom)\n",
    "                        )\n",
    "            page_number = figure.bounding_regions[0]['pageNumber']\n",
    "            cropped_img = crop_image_from_pdf_page(file, page_number - 1, bounding_box)\n",
    "\n",
    "            os.makedirs(\"figures\", exist_ok=True)\n",
    "\n",
    "            figure_filename = f\"figure_{figure_idx + 1}.png\"\n",
    "            # Full path for the file\n",
    "            figure_filepath = os.path.join(\"figures\", figure_filename)\n",
    "\n",
    "            # Save the figure\n",
    "            cropped_img.save(figure_filepath)\n",
    "            bytes_io = io.BytesIO()\n",
    "            cropped_img.save(bytes_io, format='PNG')\n",
    "            cropped_img = bytes_io.getvalue()\n",
    "\n",
    "            # Collect formatted content from the figure\n",
    "            content_understanding_response = content_understanding_client.begin_analyze(ANALYZER_ID, figure_filepath)\n",
    "            content_understanding_result = content_understanding_client.poll_result(content_understanding_response, timeout_seconds=1000)\n",
    "            figure_content = format_content_understanding_result(content_understanding_result)\n",
    "            figure_contents.append(figure_content)\n",
    "            print(f\"Figure {figure_idx + 1} contents:\\n{figure_content}\")\n",
    "\n",
    "        # Insert figure content into corresponding location in document\n",
    "        md_content = insert_figure_contents(md_content, figure_contents, [f.spans[0][\"offset\"] for f in result.figures])\n",
    "    \n",
    "    # Save results as a JSON file to cache the result for downstream use\n",
    "    result.content = md_content\n",
    "    output = {}\n",
    "    output['analyzeResult'] = result.as_dict()\n",
    "    output = json.dumps(output)\n",
    "    with open('sample_report.cache', 'w') as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the first line below to load in a previously cached result.\n",
    "# output = open(\"sample_report.cache\").read()\n",
    "document_content = json.loads(output)\n",
    "document_content = document_content['analyzeResult']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(document_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nicely print document content\n",
    "# print(document_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enhanced RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a simple (and not exhaustive) starting point. Feel free to give your own chunking strategies a try!\n",
    "\n",
    "...and replace langchain with Azure AI Foundry SDK! ðŸ˜Š\n",
    "\n",
    "In the following example:\n",
    "- we use semantic chunking to chunk the output from document intelligence (enriched with content understading on charts)\n",
    "- we use an embedding model to embed the chunks and store them in Azure AI Search for retrieval\n",
    "- we retrieve the most relevant chunks based on a sample query (e.g. \"Which is the country with the lowest GDP in 2023?\")\n",
    "- we inject the question and the retrieved content in the LLM prompt to give the LLM a context\n",
    "- we inspect the LLM response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chunk text by splitting with Markdown header splitting and recursive character splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks: 19\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Configure langchain text splitting settings\n",
    "EMBEDDING_CHUNK_SIZE = 512\n",
    "EMBEDDING_CHUNK_OVERLAP = 20\n",
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    (\"###\", \"Header 3\")\n",
    "]\n",
    "\n",
    "# First split text using Markdown headers\n",
    "text_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on, strip_headers=False)\n",
    "chunks = text_splitter.split_text(document_content)\n",
    "\n",
    "# Then further split the text using recursive character text splitting\n",
    "char_text_splitter = RecursiveCharacterTextSplitter(separators=[\"<!--\", \"\\n\\n\", \"#\"], chunk_size=EMBEDDING_CHUNK_SIZE, chunk_overlap=EMBEDDING_CHUNK_OVERLAP, is_separator_regex=True)\n",
    "chunks = char_text_splitter.split_documents(chunks)\n",
    "\n",
    "print(\"Number of chunks: \" + str(len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate embeddings and populate the Azure AI Search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model: text-embedding-3-large\n",
      "Embedding API version: 2024-10-21\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embedding model: {AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME}\")\n",
    "print(f\"Embedding API version: {AZURE_OPENAI_EMBEDDING_API_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoai_embeddings = AzureOpenAIEmbeddings(model=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "                                        azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "                                        azure_ad_token_provider=token_provider,\n",
    "                                        api_version=AZURE_OPENAI_EMBEDDING_API_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "langchain_openai.embeddings.azure.AzureOpenAIEmbeddings"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(aoai_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search endpoint: https://ep-aisearch-swedencentral-s1.search.windows.net\n",
      "Saving on index: my-index-2025-04-02\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search endpoint: {AZURE_SEARCH_ENDPOINT}\")\n",
    "print(f\"Saving on index: {AZURE_SEARCH_INDEX_NAME}-{datetime.now().strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT:\n",
    "# 1) grant user roles Search Index Data Contributor + Search Service Contributor for the Azure AI Search resource\n",
    "# 2) Settings --> Keys --> API Access Control --> select Role-based access control\n",
    "vector_store = AzureSearch(\n",
    "    azure_search_endpoint=AZURE_SEARCH_ENDPOINT,\n",
    "    azure_search_key=None,\n",
    "    index_name= AZURE_SEARCH_INDEX_NAME, #f\"{AZURE_SEARCH_INDEX_NAME}-{datetime.now().strftime('%Y-%m-%d')}\",  #\"my-first-index\",\n",
    "    embedding_function=aoai_embeddings.embed_query,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a one-time operation to add the documents to the vector store. Comment out this line if you are re-running this cell with the same index.\n",
    "vector_store.add_documents(documents=chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query vector index to retrieve relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the retriever that will be used to query the index for similar documents\n",
    "retriever = vector_store.as_retriever(search_type=\"similarity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve relevant documents\n",
    "# query = \"What was the crude oil production in 2019?\"\n",
    "query = \"What was the country with the lowest real GDP in 2023?\"\n",
    "retrieved_docs = retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document id: OTA3NGJjMGUtODM4MS00YmI1LTk0Y2UtOTVkOGUzOTNiMTQ0\n",
      "Content: <!-- FigureContent=\"**Title**: 2023 Real GDP\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Global economy\n",
      "**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, approximately 1.0%. Japan, Canada, and the Euro Area have negative deviations, each around -1.0%. The United Kingdom shows a significant negative deviation of about -4.0%. The G-20 Emerging Markets (EMs) also have a negative deviation, slightly less than -3.0%.\n",
      "**Summary**: The chart illustrates the 2023 Real GDP deviations from pre-crisis trends for several major economies. The United States is the only economy with a positive deviation, indicating growth above the pre-crisis trend. In contrast, the UK shows the largest negative deviation, suggesting a significant downturn compared to its pre-crisis trend. Other regions, including Japan, Canada, the Euro Area, and G-20 Emerging Markets, also exhibit negative deviations, indicating economic performance below pre-crisis expectations.\n",
      "**MarkdownDataTable**: | Region     | Percent Deviation |\n",
      "|------------|------------------|\n",
      "| US         | 1.0              |\n",
      "| Japan      | -1.0             |\n",
      "| Canada     | -1.0             |\n",
      "| Euro Area  | -1.0             |\n",
      "| UK         | -4.0             |\n",
      "| G-20 EMs   | -3.0             |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**:\n",
      "**AxisTitles.yAxisTitle**: Percent Deviation\n",
      "**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n",
      "\" --><figure>  \n",
      "G-20 EMs  \n",
      "</figure>  \n",
      "Sources: IMF World Economic Outlook.\n",
      "Note: Bars show the difference in real output in 2023 and anticipated output for the same\n",
      "period prior to the crisis (January 2020 WEO).\n",
      "==================================================\n",
      "Document id: Mjk0MzZkODAtNDQzNi00MDc4LWI0ODYtNDY3OTVhNzkxMWQ5\n",
      "Content: <!-- FigureContent=\"**Title**: 2023 Real GDP\n",
      "**ChartType**: bar\n",
      "**TopicKeywords**: Business and finance, Economics, Global economy\n",
      "**DetailedDescription**: The bar chart titled '2023 Real GDP' shows the percent deviation from the pre-crisis trend for various regions and countries. The United States is the only region with a positive deviation, approximately 1.0%. Japan, Canada, and the Euro Area have negative deviations, each around -1.0%. The United Kingdom shows a significant negative deviation of about -4.0%. The G-20 Emerging Markets (EMs) also have a negative deviation, slightly less than -3.0%.\n",
      "**Summary**: The chart illustrates the 2023 Real GDP deviations from pre-crisis trends for several regions. The US is the only region with a positive deviation, while the UK has the largest negative deviation. Other regions like Japan, Canada, and the Euro Area have moderate negative deviations.\n",
      "**MarkdownDataTable**: | Region     | Percent Deviation |\n",
      "|------------|------------------|\n",
      "| US         | 1.0              |\n",
      "| Japan      | -1.0             |\n",
      "| Canada     | -1.0             |\n",
      "| Euro Area  | -1.0             |\n",
      "| UK         | -4.0             |\n",
      "| G-20 EMs   | -3.0             |\n",
      "**AxisTitles**\n",
      "**AxisTitles.xAxisTitle**:\n",
      "**AxisTitles.yAxisTitle**: Percent Deviation\n",
      "**FootnotesAndAnnotations**: (percent deviation from pre-crisis trend)\n",
      "\" --><figure>  \n",
      "G-20 EMs  \n",
      "</figure>  \n",
      "Sources: IMF World Economic Outlook.\n",
      "Note: Bars show the difference in real output in 2023 and anticipated output for the same\n",
      "period prior to the crisis (January 2020 WEO).\n",
      "==================================================\n",
      "Document id: ZDFkMWE3NjYtNDk4MC00MzRkLTg2ZWItOTU4ODczZWY2Nzkz\n",
      "Content: # A RESILIENT ECONOMY  \n",
      "1\\. The U.S. economy has turned in a remarkable performance over the past few years.  \n",
      "Rather than facing lasting negative hysteresis effects from the pandemic, the U.S. is the only G20\n",
      "economy that is now operating above the levels of output and employment expected prior to the\n",
      "pandemic. Q4/Q4 growth in 2023 (at 3.1 percent)\n",
      "was almost three times that expected at the time\n",
      "2023 Real GDP\n",
      "(percent deviation from pre-crisis trend)\n",
      "of the last Article IV and core PCE inflation was\n",
      "1.0\n",
      "almost 1 percentage point lower. The rebound has\n",
      "been characterized by important gains on both the\n",
      "-0.5\n",
      "demand and supply side which has allowed\n",
      "-2.0\n",
      "inflation to head back to the FOMC's medium-term\n",
      "-3.5\n",
      "target without a major dislocation in the real\n",
      "economy. The strength of the U.S. economy and\n",
      "-5.0\n",
      "the relatively quick disinflation have had large,\n",
      "US\n",
      "Japan\n",
      "Canada\n",
      "Euro Area\n",
      "UK\n",
      "positive spillovers to the world economy.  \n",
      "\n",
      "==================================================\n",
      "Document id: ODA1YzFhYTQtYjQyMi00YTU1LWE0OTQtOGEyZGE5YTBjMzUy\n",
      "Content: # A RESILIENT ECONOMY  \n",
      "1\\. The U.S. economy has turned in a remarkable performance over the past few years.  \n",
      "Rather than facing lasting negative hysteresis effects from the pandemic, the U.S. is the only G20\n",
      "economy that is now operating above the levels of output and employment expected prior to the\n",
      "pandemic. Q4/Q4 growth in 2023 (at 3.1 percent)\n",
      "was almost three times that expected at the time\n",
      "2023 Real GDP\n",
      "(percent deviation from pre-crisis trend)\n",
      "of the last Article IV and core PCE inflation was\n",
      "1.0\n",
      "almost 1 percentage point lower. The rebound has\n",
      "been characterized by important gains on both the\n",
      "-0.5\n",
      "demand and supply side which has allowed\n",
      "-2.0\n",
      "inflation to head back to the FOMC's medium-term\n",
      "-3.5\n",
      "target without a major dislocation in the real\n",
      "economy. The strength of the U.S. economy and\n",
      "-5.0\n",
      "the relatively quick disinflation have had large,\n",
      "US\n",
      "Japan\n",
      "Canada\n",
      "Euro Area\n",
      "UK\n",
      "positive spillovers to the world economy.  \n",
      "\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Print retrieved documents\n",
    "for doc in retrieved_docs:\n",
    "    print(\"Document id:\", doc.metadata['id'])\n",
    "    print(\"Content:\", doc.page_content)\n",
    "    print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer to query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define system prompt template for chat model\n",
    "prompt = \"\"\"\n",
    "You are an expert in document analysis. You are proficient in reading and analyzing technical reports. You are good at numerical reasoning and have a good understanding of financial concepts. You are given a question which you need to answer based on the references provided. To answer this question, you may first read the question carefully to know what information is required or helpful to answer the question. Then, you may read the references to find the relevant information.\n",
    "\n",
    "If you find enough information to answer the question, you can first write down your thinking process and then provide a concise answer at the end.\n",
    "If you find that there is not enough information to answer the question, you can state that there is insufficient information.\n",
    "If you are not able or sure how to answer the question, say that you are not able to answer the question.\n",
    "Do not provide any information that is not present in the references.\n",
    "References are in markdown format, you may follow the markdown syntax to better understand the references.\n",
    "\n",
    "---\n",
    "References:\n",
    "{context}\n",
    "---\n",
    "\n",
    "Now, here is the question:\n",
    "---\n",
    "Question:\n",
    "{question}\n",
    "---\n",
    "Thinking Process::: \n",
    "Answer::: \n",
    "\"\"\"\n",
    "\n",
    "# Helper function to generate the formatted context from each retrieved document\n",
    "def generate_context(chunks):\n",
    "    context = []\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        s = (f'Source {i} Metadata: {chunk.metadata}\\n'\n",
    "                f'Source {i} Content: {chunk.page_content}')\n",
    "        context.append(s)\n",
    "    context = '\\n---\\n'.join(context)\n",
    "    return context\n",
    "\n",
    "# Remove redundant chunks\n",
    "appeared = set()\n",
    "unique_chunks = []\n",
    "for chunk in retrieved_docs:\n",
    "    chunk_id = chunk.metadata['id']\n",
    "    if chunk_id not in appeared:\n",
    "        appeared.add(chunk_id)\n",
    "        unique_chunks.append(chunk)\n",
    "context = generate_context(unique_chunks)\n",
    "\n",
    "# Format the prompt with the provided query and formatted context\n",
    "# The context is given by the retrieved documents\n",
    "prompt = prompt.format(question=query,\n",
    "                       context=context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat model: gpt-4o\n",
      "Chat API version: 2025-01-01-preview\n"
     ]
    }
   ],
   "source": [
    "print(f\"Chat model: {AZURE_OPENAI_CHAT_DEPLOYMENT_NAME}\")\n",
    "print(f\"Chat API version: {AZURE_OPENAI_CHAT_API_VERSION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = AzureChatOpenAI(model=AZURE_OPENAI_CHAT_DEPLOYMENT_NAME,\n",
    "                            azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "                            azure_ad_token_provider=token_provider,\n",
    "                            api_version=AZURE_OPENAI_CHAT_API_VERSION,\n",
    "                            temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the LLM's answer to the query with the retrieved documents as additional context\n",
    "answer = chat_llm.invoke(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Thinking Process:\n",
      "1. The question asks for the country with the lowest real GDP in 2023 based on the references provided. Specifically, it refers to the percent deviation from the pre-crisis trend.\n",
      "2. From the references, we can analyze the markdown data tables and descriptions provided about the \"2023 Real GDP\" deviations.\n",
      "3. The markdown tables and detailed descriptions indicate that the United Kingdom (UK) has the largest negative deviation of -4.0%, making it the country with the lowest real GDP in 2023 relative to its pre-crisis trend.\n",
      "4. Other regions like Japan, Canada, and the Euro Area have moderate negative deviations (-1.0%), and G-20 Emerging Markets (EMs) show a slightly larger negative deviation (-3.0%). The United States is the only region with positive deviation (+1.0%).\n",
      "\n",
      "### Answer:\n",
      "The country with the lowest real GDP in 2023, based on percent deviation from the pre-crisis trend, was the United Kingdom (UK) with a deviation of -4.0%.\n"
     ]
    }
   ],
   "source": [
    "print(answer.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cu-di-upskilling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
